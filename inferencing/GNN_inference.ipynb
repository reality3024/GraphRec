{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y03oiztMe2RU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import torch.utils.data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from math import sqrt\n",
        "import datetime\n",
        "import argparse\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7flc1wOae24l"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, embedding_dims):\n",
        "        super(Attention, self).__init__()\n",
        "        self.embed_dim = embedding_dims\n",
        "        self.bilinear = nn.Bilinear(self.embed_dim, self.embed_dim, 1)\n",
        "        self.att1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.att2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att3 = nn.Linear(self.embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(0)\n",
        "\n",
        "    def forward(self, node1, u_rep, num_neighs):\n",
        "        uv_reps = u_rep.repeat(num_neighs, 1)\n",
        "        x = torch.cat((node1, uv_reps), 1)\n",
        "        x = F.relu(self.att1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.att2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.att3(x)\n",
        "        att = F.softmax(x, dim=0)\n",
        "        return att\n",
        "\n",
        "class Social_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, social_adj_lists, aggregator, base_model=None, cuda=\"cpu\"):\n",
        "        super(Social_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.social_adj_lists = social_adj_lists\n",
        "        self.aggregator = aggregator\n",
        "        if base_model != None:\n",
        "            self.base_model = base_model\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "\n",
        "        to_neighs = []\n",
        "        for node in nodes:\n",
        "            # to_neighs.append(self.social_adj_lists[int(node)])\n",
        "            to_neighs.append(self.social_adj_lists.get(int(node), set())) # Use .get() with default empty set for missing users\n",
        "        neigh_feats = self.aggregator.forward(nodes, to_neighs)  # user-user network\n",
        "\n",
        "        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)\n",
        "        self_feats = self_feats.t()\n",
        "\n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined\n",
        "\n",
        "class Social_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    Social Aggregator: for aggregating embeddings of social neighbors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, features, u2e, embed_dim, cuda=\"cpu\"):\n",
        "        super(Social_Aggregator, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.device = cuda\n",
        "        self.u2e = u2e\n",
        "        self.embed_dim = embed_dim\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, to_neighs):\n",
        "        embed_matrix = torch.empty(len(nodes), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "        for i in range(len(nodes)):\n",
        "            tmp_adj = to_neighs[i]\n",
        "            num_neighs = len(tmp_adj)\n",
        "            #\n",
        "            e_u = self.u2e.weight[list(tmp_adj)] # fast: user embedding\n",
        "            #slow: item-space user latent factor (item aggregation)\n",
        "            #feature_neigbhors = self.features(torch.LongTensor(list(tmp_adj)).to(self.device))\n",
        "            #e_u = torch.t(feature_neigbhors)\n",
        "\n",
        "            u_rep = self.u2e.weight[nodes[i]]\n",
        "\n",
        "            att_w = self.att(e_u, u_rep, num_neighs)\n",
        "            att_history = torch.mm(e_u.t(), att_w).t()\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "\n",
        "        return to_feats\n",
        "\n",
        "class UV_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    item and user aggregator: for aggregating embeddings of neighbors (item/user aggreagator).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, v2e, r2e, u2e, embed_dim, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Aggregator, self).__init__()\n",
        "        self.uv = uv\n",
        "        self.v2e = v2e\n",
        "        self.r2e = r2e\n",
        "        self.u2e = u2e\n",
        "        self.device = cuda\n",
        "        self.embed_dim = embed_dim\n",
        "        self.w_r1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_r2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, history_uv, history_r):\n",
        "\n",
        "        embed_matrix = torch.empty(len(history_uv), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "\n",
        "        for i in range(len(history_uv)):\n",
        "            history = history_uv[i]\n",
        "            num_histroy_item = len(history)\n",
        "            tmp_label = history_r[i]\n",
        "\n",
        "            if self.uv == True:\n",
        "                # user component\n",
        "                e_uv = self.v2e.weight[history]\n",
        "                uv_rep = self.u2e.weight[nodes[i]]\n",
        "            else:\n",
        "                # item component\n",
        "                e_uv = self.u2e.weight[history]\n",
        "                uv_rep = self.v2e.weight[nodes[i]]\n",
        "\n",
        "            e_r = self.r2e.weight[tmp_label]\n",
        "            x = torch.cat((e_uv, e_r), 1)\n",
        "            x = F.relu(self.w_r1(x))\n",
        "            o_history = F.relu(self.w_r2(x))\n",
        "\n",
        "            att_w = self.att(o_history, uv_rep, num_histroy_item)\n",
        "            att_history = torch.mm(o_history.t(), att_w)\n",
        "            att_history = att_history.t()\n",
        "\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "        return to_feats\n",
        "\n",
        "class UV_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, history_uv_lists, history_r_lists, aggregator, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.uv = uv\n",
        "        self.history_uv_lists = history_uv_lists\n",
        "        self.history_r_lists = history_r_lists\n",
        "        self.aggregator = aggregator\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "        tmp_history_uv = []\n",
        "        tmp_history_r = []\n",
        "        for node in nodes:\n",
        "            tmp_history_uv.append(self.history_uv_lists[int(node)])\n",
        "            tmp_history_r.append(self.history_r_lists[int(node)])\n",
        "\n",
        "        neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r)  # user-item network\n",
        "\n",
        "        self_feats = self.features.weight[nodes]\n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined\n",
        "\n",
        "class GraphRec(nn.Module):\n",
        "\n",
        "    def __init__(self, enc_u, enc_v_history, r2e):\n",
        "        super(GraphRec, self).__init__()\n",
        "        self.enc_u = enc_u\n",
        "        self.enc_v_history = enc_v_history\n",
        "        self.embed_dim = enc_u.embed_dim\n",
        "\n",
        "        self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
        "        self.w_uv3 = nn.Linear(16, 1)\n",
        "        self.r2e = r2e\n",
        "        self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn4 = nn.BatchNorm1d(16, momentum=0.5)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, nodes_u, nodes_v):\n",
        "        embeds_u = self.enc_u(nodes_u)\n",
        "        embeds_v = self.enc_v_history(nodes_v)\n",
        "\n",
        "        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
        "        x_u = F.dropout(x_u, training=self.training)\n",
        "        x_u = self.w_ur2(x_u)\n",
        "        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
        "        x_v = F.dropout(x_v, training=self.training)\n",
        "        x_v = self.w_vr2(x_v)\n",
        "\n",
        "        x_uv = torch.cat((x_u, x_v), 1)\n",
        "        x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.bn4(self.w_uv2(x)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        scores = self.w_uv3(x)\n",
        "        return scores.squeeze()\n",
        "\n",
        "    def loss(self, nodes_u, nodes_v, labels_list):\n",
        "        scores = self.forward(nodes_u, nodes_v)\n",
        "        return self.criterion(scores, labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nDFfdBeefkUk"
      },
      "outputs": [],
      "source": [
        "def initialize_and_load_model(checkpoint_path, num_users, num_items, num_ratings, embed_dim, history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, social_adj_lists, device):\n",
        "    \"\"\"\n",
        "    Initialize model architecture and load saved weights\n",
        "    Args:\n",
        "        checkpoint_path: Path to the saved checkpoint\n",
        "        num_users: Number of users in the dataset\n",
        "        num_items: Number of items in the dataset\n",
        "        num_ratings: Number of possible ratings\n",
        "        embed_dim: Embedding dimension\n",
        "        history_u_lists: User history lists\n",
        "        history_ur_lists: User rating history lists\n",
        "        history_v_lists: Item history lists\n",
        "        history_vr_lists: Item rating history lists\n",
        "        social_adj_lists: Social adjacency lists\n",
        "        device: Device to run model on\n",
        "    Returns:\n",
        "        model: Loaded model ready for inference\n",
        "        epoch: The epoch number of the checkpoint\n",
        "        rmse: The RMSE score of the checkpoint\n",
        "        mae: The MAE score of the checkpoint\n",
        "    \"\"\"\n",
        "    # Initialize embeddings\n",
        "    u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
        "    v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
        "    r2e = nn.Embedding(num_ratings, embed_dim).to(device)\n",
        "\n",
        "    # Initialize user feature components\n",
        "    agg_u_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=True)\n",
        "    enc_u_history = UV_Encoder(u2e, embed_dim, history_u_lists, history_ur_lists, agg_u_history, cuda=device, uv=True)\n",
        "    agg_u_social = Social_Aggregator(lambda nodes: enc_u_history(nodes).t(), u2e, embed_dim, cuda=device)\n",
        "    enc_u = Social_Encoder(lambda nodes: enc_u_history(nodes).t(), embed_dim, social_adj_lists, agg_u_social,\n",
        "                          base_model=enc_u_history, cuda=device)\n",
        "\n",
        "    # Initialize item feature components\n",
        "    agg_v_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=False)\n",
        "    enc_v_history = UV_Encoder(v2e, embed_dim, history_v_lists, history_vr_lists, agg_v_history, cuda=device, uv=False)\n",
        "\n",
        "    # Initialize the model\n",
        "    model = GraphRec(enc_u, enc_v_history, r2e).to(device)\n",
        "\n",
        "    # Load the saved weights\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    rmse = checkpoint['rmse']\n",
        "    mae = checkpoint['mae']\n",
        "\n",
        "    return model, epoch, rmse, mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oj4DDgT8fU3X"
      },
      "outputs": [],
      "source": [
        "def load_model(checkpoint_path, model, optimizer=None):\n",
        "    \"\"\"\n",
        "    Load a saved model checkpoint\n",
        "    Args:\n",
        "        checkpoint_path: Path to the saved checkpoint\n",
        "        model: The model instance to load weights into\n",
        "        optimizer: Optional optimizer to load state\n",
        "    Returns:\n",
        "        model: Loaded model\n",
        "        optimizer: Loaded optimizer (if provided)\n",
        "        epoch: The epoch number of the checkpoint\n",
        "        rmse: The RMSE score of the checkpoint\n",
        "        mae: The MAE score of the checkpoint\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    rmse = checkpoint['rmse']\n",
        "    mae = checkpoint['mae']\n",
        "    return model, optimizer, epoch, rmse, mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lB54TYi9fomL"
      },
      "outputs": [],
      "source": [
        "def create_result(user_ids, item_ids, predicted_ratings_continuous, predicted_ratings_round, predicted_ratings, key_rating, value_rating, rmse, mae):\n",
        "    # Create a DataFrame\n",
        "    data = {\n",
        "        'user_id': user_ids,\n",
        "        'item': item_ids,\n",
        "        'predicted_rating_continuous': predicted_ratings_continuous,\n",
        "        'predicted_rating_round': predicted_ratings_round,\n",
        "        'target_key': key_rating,\n",
        "        'predicted_rating': predicted_ratings,\n",
        "        'target_label': value_rating\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Create the result directory if it doesn't exist\n",
        "    result_dir = 'result'\n",
        "    if not os.path.exists(result_dir):\n",
        "        os.makedirs(result_dir)\n",
        "    \n",
        "    # Export metrics to a text file\n",
        "    metrics_file_path = os.path.join(result_dir, 'metrics.txt')\n",
        "    with open(metrics_file_path, 'w') as f:\n",
        "        f.write(f\"RMSE: {rmse:.4f}\\n\")\n",
        "        f.write(f\"MAE: {mae:.4f}\\n\")\n",
        "    print(f\"Metrics exported to {metrics_file_path}\")\n",
        "\n",
        "    # Specify the path for the CSV file\n",
        "    csv_file_path = os.path.join(result_dir, 'predictions.csv')\n",
        "\n",
        "    # Export to CSV\n",
        "    df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "    print(f\"Data exported to {csv_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GI825AbTnGtX"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader, ratings_list):\n",
        "    model.eval()\n",
        "    user_id_list = []\n",
        "    item_id_list = []\n",
        "    tmp_pred = []\n",
        "    target = []\n",
        "    predictions = []\n",
        "    rounded_ratings = []\n",
        "    actual_targets = []\n",
        "    with torch.no_grad():\n",
        "        for test_u, test_v, tmp_target in tqdm(test_loader, desc=\"Testing\"):\n",
        "            test_u, test_v, tmp_target = test_u.to(device), test_v.to(device), tmp_target.to(device)\n",
        "            val_output = model.forward(test_u, test_v)\n",
        "            user_id_list.extend(test_u.tolist())\n",
        "            item_id_list.extend(test_v.tolist())\n",
        "            tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
        "            target.append(list(tmp_target.data.cpu().numpy()))\n",
        "    tmp_pred = np.array(sum(tmp_pred, []))\n",
        "    target = np.array(sum(target, []))\n",
        "    expected_rmse = sqrt(mean_squared_error(tmp_pred, target))\n",
        "    mae = mean_absolute_error(tmp_pred, target)\n",
        "\n",
        "    # Convert the continuous value to the nearest key of ratings_list\n",
        "    for i in range(len(tmp_pred)):\n",
        "        predicted_rating = tmp_pred[i]\n",
        "        rounded_rating = min(ratings_list.keys(), key=lambda x: abs(x - predicted_rating))\n",
        "        rounded_ratings.append(rounded_rating)\n",
        "        # Get the corresponding value from ratings_list\n",
        "        final_prediction = ratings_list[rounded_rating]\n",
        "        predictions.append(final_prediction)\n",
        "    for i in range(len(target)):\n",
        "        actual_target = target[i]\n",
        "        actual_targets.append(ratings_list[actual_target])\n",
        "    return user_id_list, item_id_list, expected_rmse, mae, tmp_pred, rounded_ratings, predictions, target, actual_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB73p4E5frVi",
        "outputId": "1b6e5b66-ba39-4680-e1b8-6bc717e56cc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2336761/2119905480.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User num:22167\n",
            "Item  num:296278\n",
            "Rating list num:6\n",
            "Loaded model from epoch 10 with RMSE: 0.8246, MAE: 0.5776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 93/93 [00:33<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics exported to result/metrics.txt\n",
            "Data exported to result/predictions.csv\n",
            "Expected RMSE: 0.8218, MAE: 0.5762\n"
          ]
        }
      ],
      "source": [
        "# 1. First load your dataset\n",
        "dir_data = './data/Epinions/dataset_Epinions_train80val10test10'\n",
        "path_data = dir_data + \".pickle\"\n",
        "data_file = open(path_data, 'rb')\n",
        "# history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, train_u, train_v, train_r, test_u, test_v, test_r, social_adj_lists, ratings_list = pickle.load(data_file)\n",
        "history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, train_u, train_v, train_r, val_u, val_v, val_r, test_u, test_v, test_r, social_adj_lists, ratings_list, history_timestamp_lists = pickle.load(data_file)\n",
        "testset = torch.utils.data.TensorDataset(torch.LongTensor(test_u), torch.LongTensor(test_v),torch.FloatTensor(test_r))\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=True)\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "use_cuda = False\n",
        "if torch.cuda.is_available():\n",
        "\tuse_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# 2. Get the dimensions\n",
        "num_users = len(history_u_lists)\n",
        "num_items = len(history_v_lists)\n",
        "num_ratings = len(ratings_list)\n",
        "print(f'User num:{num_users}')\n",
        "print(f'Item  num:{num_items}')\n",
        "print(f'Rating list num:{num_ratings}')\n",
        "embed_dim = 64  # Should match your training configuration\n",
        "\n",
        "# 3. Initialize and load the model\n",
        "best_model_path = './checkpoints/best_model.pt'\n",
        "model, epoch, rmse, mae = initialize_and_load_model(\n",
        "    best_model_path,\n",
        "    num_users,\n",
        "    num_items,\n",
        "    num_ratings,\n",
        "    embed_dim,\n",
        "    history_u_lists,\n",
        "    history_ur_lists,\n",
        "    history_v_lists,\n",
        "    history_vr_lists,\n",
        "    social_adj_lists,\n",
        "    device\n",
        ")\n",
        "\n",
        "print(f\"Loaded model from epoch {epoch} with RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
        "# 4. inference model\n",
        "userID_list, itemID_list, expected_rmse, mae, predicted_ratings_continuous, predicted_ratings_round, predicted_ratings, key_ratings, value_ratings = test(model, device, test_loader, ratings_list)\n",
        "# create csv result\n",
        "create_result(userID_list, itemID_list, predicted_ratings_continuous, predicted_ratings_round, predicted_ratings, key_ratings, value_ratings,expected_rmse,mae)\n",
        "\n",
        "print(f\"Expected RMSE: {expected_rmse:.4f}, MAE: {mae:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GraphRec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
