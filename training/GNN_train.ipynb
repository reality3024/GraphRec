{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9P9qWhobX6o"
      },
      "source": [
        "# Create API to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTZI7qpTWE6a",
        "outputId": "33d381a8-9c78-4e88-82c0-66b6b7c8b2af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17mv08p9WchJ",
        "outputId": "e201f53d-e575-4ea6-b2e5-26c93ff25589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive\n",
        "!mkdir Epinions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw02vWCGbLNK"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxk77J8yZuPt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import torch.utils.data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from math import sqrt\n",
        "import datetime\n",
        "import argparse\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcJ24B1QbP2X"
      },
      "source": [
        "# Define Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq8FTov7aSHW"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, embedding_dims):\n",
        "        super(Attention, self).__init__()\n",
        "        self.embed_dim = embedding_dims\n",
        "        self.bilinear = nn.Bilinear(self.embed_dim, self.embed_dim, 1)\n",
        "        self.att1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.att2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att3 = nn.Linear(self.embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(0)\n",
        "\n",
        "    def forward(self, node1, u_rep, num_neighs):\n",
        "        uv_reps = u_rep.repeat(num_neighs, 1)\n",
        "        x = torch.cat((node1, uv_reps), 1)\n",
        "        x = F.relu(self.att1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.att2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.att3(x)\n",
        "        att = F.softmax(x, dim=0)\n",
        "        return att"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubEsXapZaToS"
      },
      "outputs": [],
      "source": [
        "class Social_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, social_adj_lists, aggregator, base_model=None, cuda=\"cpu\"):\n",
        "        super(Social_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.social_adj_lists = social_adj_lists\n",
        "        self.aggregator = aggregator\n",
        "        if base_model != None:\n",
        "            self.base_model = base_model\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "\n",
        "        to_neighs = []\n",
        "        for node in nodes:\n",
        "            # to_neighs.append(self.social_adj_lists[int(node)])\n",
        "            to_neighs.append(self.social_adj_lists.get(int(node), set())) # Use .get() with default empty set for missing users\n",
        "        neigh_feats = self.aggregator.forward(nodes, to_neighs)  # user-user network\n",
        "\n",
        "        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)\n",
        "        self_feats = self_feats.t()\n",
        "\n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "162geY4UaWO4"
      },
      "outputs": [],
      "source": [
        "class Social_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    Social Aggregator: for aggregating embeddings of social neighbors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, features, u2e, embed_dim, cuda=\"cpu\"):\n",
        "        super(Social_Aggregator, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.device = cuda\n",
        "        self.u2e = u2e\n",
        "        self.embed_dim = embed_dim\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, to_neighs):\n",
        "        embed_matrix = torch.empty(len(nodes), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "        for i in range(len(nodes)):\n",
        "            tmp_adj = to_neighs[i]\n",
        "            num_neighs = len(tmp_adj)\n",
        "            e_u = self.u2e.weight[list(tmp_adj)] # fast: user embedding\n",
        "            #slow: item-space user latent factor (item aggregation)\n",
        "            #feature_neigbhors = self.features(torch.LongTensor(list(tmp_adj)).to(self.device))\n",
        "            #e_u = torch.t(feature_neigbhors)\n",
        "\n",
        "            u_rep = self.u2e.weight[nodes[i]]\n",
        "\n",
        "            att_w = self.att(e_u, u_rep, num_neighs)\n",
        "            att_history = torch.mm(e_u.t(), att_w).t()\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "\n",
        "        return to_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWlis_Kgadle"
      },
      "outputs": [],
      "source": [
        "class UV_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    item and user aggregator: for aggregating embeddings of neighbors (item/user aggreagator).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, v2e, r2e, u2e, embed_dim, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Aggregator, self).__init__()\n",
        "        self.uv = uv\n",
        "        self.v2e = v2e\n",
        "        self.r2e = r2e\n",
        "        self.u2e = u2e\n",
        "        self.device = cuda\n",
        "        self.embed_dim = embed_dim\n",
        "        self.w_r1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_r2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, history_uv, history_r):\n",
        "\n",
        "        embed_matrix = torch.empty(len(history_uv), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "\n",
        "        for i in range(len(history_uv)):\n",
        "            history = history_uv[i]\n",
        "            num_histroy_item = len(history)\n",
        "            tmp_label = history_r[i]\n",
        "\n",
        "            if self.uv == True:\n",
        "                # user component\n",
        "                e_uv = self.v2e.weight[history]\n",
        "                uv_rep = self.u2e.weight[nodes[i]]\n",
        "            else:\n",
        "                # item component\n",
        "                e_uv = self.u2e.weight[history]\n",
        "                uv_rep = self.v2e.weight[nodes[i]]\n",
        "\n",
        "            e_r = self.r2e.weight[tmp_label]\n",
        "            x = torch.cat((e_uv, e_r), 1)\n",
        "            x = F.relu(self.w_r1(x))\n",
        "            o_history = F.relu(self.w_r2(x))\n",
        "\n",
        "            att_w = self.att(o_history, uv_rep, num_histroy_item)\n",
        "            att_history = torch.mm(o_history.t(), att_w)\n",
        "            att_history = att_history.t()\n",
        "\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "        return to_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y4oueU0aiTo"
      },
      "outputs": [],
      "source": [
        "class UV_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, history_uv_lists, history_r_lists, aggregator, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.uv = uv\n",
        "        self.history_uv_lists = history_uv_lists\n",
        "        self.history_r_lists = history_r_lists\n",
        "        self.aggregator = aggregator\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "        tmp_history_uv = []\n",
        "        tmp_history_r = []\n",
        "        for node in nodes:\n",
        "            tmp_history_uv.append(self.history_uv_lists[int(node)])\n",
        "            tmp_history_r.append(self.history_r_lists[int(node)])\n",
        "\n",
        "        neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r)  # user-item network\n",
        "\n",
        "        self_feats = self.features.weight[nodes]\n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjsZUFEDa6q0"
      },
      "source": [
        "# Main Code\n",
        "\n",
        "> GraphRec Definition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eDi8vn1av5E"
      },
      "outputs": [],
      "source": [
        "class GraphRec(nn.Module):\n",
        "\n",
        "    def __init__(self, enc_u, enc_v_history, r2e):\n",
        "        super(GraphRec, self).__init__()\n",
        "        self.enc_u = enc_u\n",
        "        self.enc_v_history = enc_v_history\n",
        "        self.embed_dim = enc_u.embed_dim\n",
        "\n",
        "        self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
        "        self.w_uv3 = nn.Linear(16, 1)\n",
        "        self.r2e = r2e\n",
        "        self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn4 = nn.BatchNorm1d(16, momentum=0.5)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, nodes_u, nodes_v):\n",
        "        embeds_u = self.enc_u(nodes_u)\n",
        "        embeds_v = self.enc_v_history(nodes_v)\n",
        "\n",
        "        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
        "        x_u = F.dropout(x_u, training=self.training)\n",
        "        x_u = self.w_ur2(x_u)\n",
        "        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
        "        x_v = F.dropout(x_v, training=self.training)\n",
        "        x_v = self.w_vr2(x_v)\n",
        "\n",
        "        x_uv = torch.cat((x_u, x_v), 1)\n",
        "        x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.bn4(self.w_uv2(x)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        scores = self.w_uv3(x)\n",
        "        return scores.squeeze()\n",
        "\n",
        "    def loss(self, nodes_u, nodes_v, labels_list):\n",
        "        scores = self.forward(nodes_u, nodes_v)\n",
        "        return self.criterion(scores, labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofzWjcW2axiU"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, best_rmse, best_mae):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        batch_nodes_u, batch_nodes_v, labels_list = data\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(batch_nodes_u.to(device), batch_nodes_v.to(device), labels_list.to(device))\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            print('[%d, %5d] loss: %.3f, The best rmse/mae: %.6f / %.6f' % (\n",
        "                epoch, i, running_loss / 100, best_rmse, best_mae))\n",
        "            running_loss = 0.0\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0CYf8_uccvj"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    tmp_pred = []\n",
        "    target = []\n",
        "    with torch.no_grad():\n",
        "        for test_u, test_v, tmp_target in test_loader:\n",
        "            test_u, test_v, tmp_target = test_u.to(device), test_v.to(device), tmp_target.to(device)\n",
        "            val_output = model.forward(test_u, test_v)\n",
        "            tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
        "            target.append(list(tmp_target.data.cpu().numpy()))\n",
        "    tmp_pred = np.array(sum(tmp_pred, []))\n",
        "    target = np.array(sum(target, []))\n",
        "    expected_rmse = sqrt(mean_squared_error(tmp_pred, target))\n",
        "    mae = mean_absolute_error(tmp_pred, target)\n",
        "    return expected_rmse, mae"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_checkpoint_dir():\n",
        "    checkpoint_dir = './checkpoints'\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    return checkpoint_dir"
      ],
      "metadata": {
        "id": "E_jaTl80RU0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, epoch, rmse, mae, checkpoint_dir, is_best=False):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'rmse': rmse,\n",
        "        'mae': mae\n",
        "    }\n",
        "\n",
        "    # Save regular checkpoint\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint.pt')\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "    # Save best model if it's the best so far\n",
        "    if is_best:\n",
        "        best_model_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
        "        torch.save(checkpoint, best_model_path)\n",
        "        print(f\"New best model saved! RMSE: {rmse:.4f}, MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "id": "UL61yawhRXqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iBvwXMkcfAv",
        "outputId": "59874b6f-b156-4c81-fc97-ddf1ae681278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total epoch:100\n",
            "[1,     0] loss: 0.082, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   100] loss: 5.724, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "New best model saved! RMSE: 2.1073, MAE: 1.9398\n",
            "rmse: 2.1073, mae:1.9398 \n",
            "[2,     0] loss: 0.036, The best rmse/mae: 2.107251 / 1.939837\n",
            "[2,   100] loss: 2.789, The best rmse/mae: 2.107251 / 1.939837\n",
            "New best model saved! RMSE: 1.3467, MAE: 1.1783\n",
            "rmse: 1.3467, mae:1.1783 \n",
            "[3,     0] loss: 0.024, The best rmse/mae: 1.346707 / 1.178300\n",
            "[3,   100] loss: 1.895, The best rmse/mae: 1.346707 / 1.178300\n",
            "New best model saved! RMSE: 1.1284, MAE: 0.9275\n",
            "rmse: 1.1284, mae:0.9275 \n",
            "[4,     0] loss: 0.015, The best rmse/mae: 1.128430 / 0.927519\n",
            "[4,   100] loss: 1.439, The best rmse/mae: 1.128430 / 0.927519\n",
            "New best model saved! RMSE: 0.8840, MAE: 0.7033\n",
            "rmse: 0.8840, mae:0.7033 \n",
            "[5,     0] loss: 0.014, The best rmse/mae: 0.883964 / 0.703265\n",
            "[5,   100] loss: 1.187, The best rmse/mae: 0.883964 / 0.703265\n",
            "rmse: 1.2126, mae:0.9568 \n",
            "[6,     0] loss: 0.011, The best rmse/mae: 0.883964 / 0.703265\n",
            "[6,   100] loss: 1.038, The best rmse/mae: 0.883964 / 0.703265\n",
            "rmse: 0.8915, mae:0.6771 \n",
            "[7,     0] loss: 0.010, The best rmse/mae: 0.883964 / 0.703265\n",
            "[7,   100] loss: 0.975, The best rmse/mae: 0.883964 / 0.703265\n",
            "New best model saved! RMSE: 0.8739, MAE: 0.6573\n",
            "rmse: 0.8739, mae:0.6573 \n",
            "[8,     0] loss: 0.010, The best rmse/mae: 0.873927 / 0.657341\n",
            "[8,   100] loss: 0.907, The best rmse/mae: 0.873927 / 0.657341\n",
            "rmse: 0.9071, mae:0.6695 \n",
            "[9,     0] loss: 0.007, The best rmse/mae: 0.873927 / 0.657341\n",
            "[9,   100] loss: 0.867, The best rmse/mae: 0.873927 / 0.657341\n",
            "rmse: 0.9616, mae:0.7088 \n",
            "[10,     0] loss: 0.008, The best rmse/mae: 0.873927 / 0.657341\n",
            "[10,   100] loss: 0.840, The best rmse/mae: 0.873927 / 0.657341\n",
            "New best model saved! RMSE: 0.8214, MAE: 0.6380\n",
            "rmse: 0.8214, mae:0.6380 \n",
            "[11,     0] loss: 0.007, The best rmse/mae: 0.821386 / 0.637998\n",
            "[11,   100] loss: 0.813, The best rmse/mae: 0.821386 / 0.637998\n",
            "rmse: 0.8244, mae:0.6269 \n",
            "[12,     0] loss: 0.008, The best rmse/mae: 0.821386 / 0.637998\n",
            "[12,   100] loss: 0.789, The best rmse/mae: 0.821386 / 0.637998\n",
            "rmse: 0.8482, mae:0.6402 \n",
            "[13,     0] loss: 0.008, The best rmse/mae: 0.821386 / 0.637998\n",
            "[13,   100] loss: 0.767, The best rmse/mae: 0.821386 / 0.637998\n",
            "rmse: 0.8300, mae:0.6284 \n",
            "[14,     0] loss: 0.008, The best rmse/mae: 0.821386 / 0.637998\n",
            "[14,   100] loss: 0.747, The best rmse/mae: 0.821386 / 0.637998\n",
            "New best model saved! RMSE: 0.8138, MAE: 0.6311\n",
            "rmse: 0.8138, mae:0.6311 \n",
            "[15,     0] loss: 0.007, The best rmse/mae: 0.813801 / 0.631127\n",
            "[15,   100] loss: 0.736, The best rmse/mae: 0.813801 / 0.631127\n",
            "rmse: 0.8545, mae:0.6663 \n",
            "[16,     0] loss: 0.006, The best rmse/mae: 0.813801 / 0.631127\n",
            "[16,   100] loss: 0.704, The best rmse/mae: 0.813801 / 0.631127\n",
            "rmse: 0.8274, mae:0.6254 \n",
            "[17,     0] loss: 0.007, The best rmse/mae: 0.813801 / 0.631127\n",
            "[17,   100] loss: 0.693, The best rmse/mae: 0.813801 / 0.631127\n",
            "New best model saved! RMSE: 0.8064, MAE: 0.6251\n",
            "rmse: 0.8064, mae:0.6251 \n",
            "[18,     0] loss: 0.008, The best rmse/mae: 0.806423 / 0.625094\n",
            "[18,   100] loss: 0.681, The best rmse/mae: 0.806423 / 0.625094\n",
            "rmse: 0.8181, mae:0.6234 \n",
            "[19,     0] loss: 0.007, The best rmse/mae: 0.806423 / 0.625094\n",
            "[19,   100] loss: 0.666, The best rmse/mae: 0.806423 / 0.625094\n",
            "rmse: 0.8255, mae:0.6358 \n",
            "[20,     0] loss: 0.007, The best rmse/mae: 0.806423 / 0.625094\n",
            "[20,   100] loss: 0.666, The best rmse/mae: 0.806423 / 0.625094\n",
            "rmse: 0.8276, mae:0.6419 \n",
            "[21,     0] loss: 0.008, The best rmse/mae: 0.806423 / 0.625094\n",
            "[21,   100] loss: 0.652, The best rmse/mae: 0.806423 / 0.625094\n",
            "rmse: 0.8174, mae:0.6277 \n",
            "[22,     0] loss: 0.006, The best rmse/mae: 0.806423 / 0.625094\n",
            "[22,   100] loss: 0.641, The best rmse/mae: 0.806423 / 0.625094\n",
            "rmse: 0.8088, mae:0.6254 \n",
            "[23,     0] loss: 0.005, The best rmse/mae: 0.806423 / 0.625094\n",
            "[23,   100] loss: 0.642, The best rmse/mae: 0.806423 / 0.625094\n",
            "rmse: 0.8087, mae:0.6297 \n"
          ]
        }
      ],
      "source": [
        "# Define the arguments as a dictionary\n",
        "args_dict = {\n",
        "    '--batch_size': 128,\n",
        "    '--embed_dim': 64,\n",
        "    '--lr': 0.001,\n",
        "    '--test_batch_size': 1000,\n",
        "    '--epochs': 100\n",
        "}\n",
        "\n",
        "# Create a list of strings from the dictionary\n",
        "args_list = []\n",
        "for k, v in args_dict.items():\n",
        "    args_list.append(k)\n",
        "    args_list.append(str(v))\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Social Recommendation: GraphRec model')\n",
        "parser.add_argument('--batch_size', type=int, default=128, metavar='N', help='input batch size for training')\n",
        "parser.add_argument('--embed_dim', type=int, default=64, metavar='N', help='embedding size')\n",
        "parser.add_argument('--lr', type=float, default=0.001, metavar='LR', help='learning rate')\n",
        "parser.add_argument('--test_batch_size', type=int, default=1000, metavar='N', help='input batch size for testing')\n",
        "parser.add_argument('--epochs', type=int, default=100, metavar='N', help='number of epochs to train')\n",
        "args = parser.parse_args(args_list) # Pass the list to parse_args\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "use_cuda = False\n",
        "if torch.cuda.is_available():\n",
        "\tuse_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "embed_dim = args.embed_dim\n",
        "# dir_data = './Epinions/dataset_Epinions'\n",
        "dir_data = './Epinions/toy_dataset'\n",
        "\n",
        "path_data = dir_data + \".pickle\"\n",
        "data_file = open(path_data, 'rb')\n",
        "history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, train_u, train_v, train_r, test_u, test_v, test_r, social_adj_lists, ratings_list = pickle.load(\n",
        "\tdata_file)\n",
        "\"\"\"\n",
        "## toy dataset\n",
        "history_u_lists, history_ur_lists:  user's purchased history (item set in training set), and his/her rating score (dict)\n",
        "history_v_lists, history_vr_lists:  user set (in training set) who have interacted with the item, and rating score (dict)\n",
        "\n",
        "train_u, train_v, train_r: training_set (user, item, rating)\n",
        "test_u, test_v, test_r: testing set (user, item, rating)\n",
        "\n",
        "# please add the validation set\n",
        "\n",
        "social_adj_lists: user's connected neighborhoods\n",
        "ratings_list: rating value from 0.5 to 4.0 (8 opinion embeddings)\n",
        "\"\"\"\n",
        "\n",
        "trainset = torch.utils.data.TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v),\n",
        "\t\t\t\t\t\t\t\t\t\t  torch.FloatTensor(train_r))\n",
        "testset = torch.utils.data.TensorDataset(torch.LongTensor(test_u), torch.LongTensor(test_v),\n",
        "\t\t\t\t\t\t\t\t\t\t torch.FloatTensor(test_r))\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=True)\n",
        "num_users = history_u_lists.__len__()\n",
        "num_items = history_v_lists.__len__()\n",
        "num_ratings = ratings_list.__len__()\n",
        "\n",
        "u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
        "v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
        "r2e = nn.Embedding(num_ratings, embed_dim).to(device)\n",
        "\n",
        "# user feature\n",
        "# features: item * rating\n",
        "agg_u_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=True)\n",
        "enc_u_history = UV_Encoder(u2e, embed_dim, history_u_lists, history_ur_lists, agg_u_history, cuda=device, uv=True)\n",
        "# neighobrs\n",
        "agg_u_social = Social_Aggregator(lambda nodes: enc_u_history(nodes).t(), u2e, embed_dim, cuda=device)\n",
        "enc_u = Social_Encoder(lambda nodes: enc_u_history(nodes).t(), embed_dim, social_adj_lists, agg_u_social,\n",
        "\t\t\t\t\t   base_model=enc_u_history, cuda=device)\n",
        "\n",
        "# item feature: user * rating\n",
        "agg_v_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=False)\n",
        "enc_v_history = UV_Encoder(v2e, embed_dim, history_v_lists, history_vr_lists, agg_v_history, cuda=device, uv=False)\n",
        "\n",
        "# model\n",
        "graphrec = GraphRec(enc_u, enc_v_history, r2e).to(device)\n",
        "optimizer = torch.optim.RMSprop(graphrec.parameters(), lr=args.lr, alpha=0.9)\n",
        "\n",
        "# Create checkpoint directory\n",
        "checkpoint_dir = create_checkpoint_dir()\n",
        "\n",
        "best_rmse = 9999.0\n",
        "best_mae = 9999.0\n",
        "endure_count = 0\n",
        "\n",
        "print(f'total epoch:{args.epochs}')\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "\n",
        "\ttrain(graphrec, device, train_loader, optimizer, epoch, best_rmse, best_mae)\n",
        "\texpected_rmse, mae = test(graphrec, device, test_loader)\n",
        "\t# please add the validation set to tune the hyper-parameters based on your datasets.\n",
        "\n",
        "\t# early stopping (no validation set in toy dataset)\n",
        "\tif best_rmse > expected_rmse:\n",
        "\t\tbest_rmse = expected_rmse\n",
        "\t\tbest_mae = mae\n",
        "\t\tendure_count = 0\n",
        "\t\t# Save best model\n",
        "\t\tsave_checkpoint(graphrec, optimizer, epoch, expected_rmse, mae, checkpoint_dir, is_best=True)\n",
        "\telse:\n",
        "\t\tendure_count += 1\n",
        "\tprint(\"rmse: %.4f, mae:%.4f \" % (expected_rmse, mae))\n",
        "\n",
        "\tif endure_count > 5:\n",
        "\t\tbreak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KryxG0vQeYaZ"
      },
      "source": [
        "# 結果如上"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}