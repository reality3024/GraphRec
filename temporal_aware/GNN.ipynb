{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw02vWCGbLNK"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gxk77J8yZuPt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import torch.utils.data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from math import sqrt\n",
        "import datetime\n",
        "import argparse\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import logging\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcJ24B1QbP2X"
      },
      "source": [
        "# Define Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wK1PCIESJRA0"
      },
      "outputs": [],
      "source": [
        "def setup_logging():\n",
        "    # Create logs directory if it doesn't exist\n",
        "    log_dir = os.path.join(os.getcwd(), 'logs')\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "\n",
        "    # Create a log file with timestamp\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    log_file = os.path.join(log_dir, f'training_log_{timestamp}.txt')\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file, encoding='utf-8'),\n",
        "            logging.StreamHandler()  # This will also print to console\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Create logger\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Log the start of a new training session\n",
        "    logger.info(\"=\"*50)\n",
        "    logger.info(\"New Training Session Started\")\n",
        "    logger.info(\"=\"*50)\n",
        "    logger.info(f\"Log file created at: {log_file}\")\n",
        "\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aq8FTov7aSHW"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, embedding_dims):\n",
        "        super(Attention, self).__init__()\n",
        "        self.embed_dim = embedding_dims\n",
        "        self.bilinear = nn.Bilinear(self.embed_dim, self.embed_dim, 1)\n",
        "        self.att1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.att2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att3 = nn.Linear(self.embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(0)\n",
        "\n",
        "    def forward(self, node1, u_rep, num_neighs):\n",
        "        uv_reps = u_rep.repeat(num_neighs, 1)\n",
        "        x = torch.cat((node1, uv_reps), 1)\n",
        "        x = F.relu(self.att1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.att2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.att3(x)\n",
        "        att = F.softmax(x, dim=0)\n",
        "        return att"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ubEsXapZaToS"
      },
      "outputs": [],
      "source": [
        "class Social_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, social_adj_lists, aggregator, base_model=None, cuda=\"cpu\"):\n",
        "        super(Social_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.social_adj_lists = social_adj_lists\n",
        "        self.aggregator = aggregator\n",
        "        if base_model != None:\n",
        "            self.base_model = base_model\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "\n",
        "        to_neighs = []\n",
        "        for node in nodes:\n",
        "            # to_neighs.append(self.social_adj_lists[int(node)])\n",
        "            to_neighs.append(self.social_adj_lists.get(int(node), set())) # Use .get() with default empty set for missing users\n",
        "        neigh_feats = self.aggregator.forward(nodes, to_neighs)  # user-user network\n",
        "\n",
        "        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)\n",
        "        self_feats = self_feats.t()\n",
        "\n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "162geY4UaWO4"
      },
      "outputs": [],
      "source": [
        "class Social_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    Social Aggregator: for aggregating embeddings of social neighbors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, features, u2e, embed_dim, cuda=\"cpu\"):\n",
        "        super(Social_Aggregator, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.device = cuda\n",
        "        self.u2e = u2e\n",
        "        self.embed_dim = embed_dim\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, to_neighs):\n",
        "        embed_matrix = torch.empty(len(nodes), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "        for i in range(len(nodes)):\n",
        "            tmp_adj = to_neighs[i]\n",
        "            num_neighs = len(tmp_adj)\n",
        "            e_u = self.u2e.weight[list(tmp_adj)] # fast: user embedding\n",
        "            #slow: item-space user latent factor (item aggregation)\n",
        "            #feature_neigbhors = self.features(torch.LongTensor(list(tmp_adj)).to(self.device))\n",
        "            #e_u = torch.t(feature_neigbhors)\n",
        "\n",
        "            u_rep = self.u2e.weight[nodes[i]]\n",
        "\n",
        "            att_w = self.att(e_u, u_rep, num_neighs)\n",
        "            att_history = torch.mm(e_u.t(), att_w).t()\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "\n",
        "        return to_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sWlis_Kgadle"
      },
      "outputs": [],
      "source": [
        "class UV_Aggregator(nn.Module):\n",
        "    def __init__(self, v2e, r2e, u2e, history_t, lamda, embed_dim, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Aggregator, self).__init__()\n",
        "        self.uv = uv\n",
        "        self.v2e = v2e\n",
        "        self.r2e = r2e\n",
        "        self.u2e = u2e\n",
        "        self.device = cuda\n",
        "        self.embed_dim = embed_dim\n",
        "        self.w_r1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_r2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att = Attention(self.embed_dim)\n",
        "        self.lamda = lamda\n",
        "        self.history_t = history_t\n",
        "\n",
        "    def forward(self, nodes, history_uv, history_r, history_userID):\n",
        "        embed_matrix = torch.empty(len(history_uv), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "        for i in range(len(history_uv)):\n",
        "            history = history_uv[i]\n",
        "            num_histroy_item = len(history)\n",
        "            tmp_label = history_r[i]\n",
        "            user_id = history_userID[i]\n",
        "\n",
        "            if self.uv == True:\n",
        "                e_uv = self.v2e.weight[history]\n",
        "                uv_rep = self.u2e.weight[nodes[i]]\n",
        "            else:\n",
        "                e_uv = self.u2e.weight[history]\n",
        "                uv_rep = self.v2e.weight[nodes[i]]\n",
        "\n",
        "            e_r = self.r2e.weight[tmp_label]\n",
        "            x = torch.cat((e_uv, e_r), 1)\n",
        "            x = F.relu(self.w_r1(x))\n",
        "            o_history = F.relu(self.w_r2(x))\n",
        "\n",
        "            att_w = self.att(o_history, uv_rep, num_histroy_item)\n",
        "\n",
        "            if self.history_t is not None and self.uv == True:\n",
        "                timestamps = self.history_t[user_id]\n",
        "                timestamps = torch.tensor(timestamps, dtype=torch.float, device=att_w.device)\n",
        "                max_time = timestamps.max()\n",
        "                t_diff = max_time - timestamps\n",
        "\n",
        "                # Add safety checks\n",
        "                if torch.isnan(t_diff).any() or torch.isinf(t_diff).any():\n",
        "                    print(f\"Warning: Invalid t_diff values detected: {t_diff}\")\n",
        "                    t_diff = torch.clamp(t_diff, min=0.0, max=100.0)  # Clamp to reasonable range\n",
        "\n",
        "                time_decay = torch.exp(-self.lamda * t_diff)\n",
        "\n",
        "                # Check for invalid values in time_decay\n",
        "                if torch.isnan(time_decay).any() or torch.isinf(time_decay).any():\n",
        "                    print(f\"Warning: Invalid time_decay values detected: {time_decay}\")\n",
        "                    time_decay = torch.clamp(time_decay, min=1e-10, max=1.0)  # Clamp to reasonable range\n",
        "\n",
        "                att_w = att_w.squeeze() * time_decay\n",
        "\n",
        "                # Check for zero sum\n",
        "                att_sum = att_w.sum()\n",
        "                if att_sum == 0:\n",
        "                    print(f\"Warning: Zero sum in attention weights: {att_w}\")\n",
        "                    att_w = torch.ones_like(att_w) / att_w.size(0)  # Use uniform distribution as fallback\n",
        "                else:\n",
        "                    att_w = att_w / att_sum\n",
        "\n",
        "                att_w = att_w.unsqueeze(1)\n",
        "\n",
        "            att_history = torch.mm(o_history.t(), att_w)\n",
        "            att_history = att_history.t()\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "        return to_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1Y4oueU0aiTo"
      },
      "outputs": [],
      "source": [
        "class UV_Encoder(nn.Module):\n",
        "    def __init__(self, features, embed_dim, history_uv_lists, history_r_lists, history_t, aggregator, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Encoder, self).__init__()\n",
        "        self.features = features\n",
        "        self.uv = uv\n",
        "        self.history_uv_lists = history_uv_lists\n",
        "        self.history_r_lists = history_r_lists\n",
        "        self.aggregator = aggregator\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)\n",
        "        self.history_t = history_t\n",
        "\n",
        "    def forward(self, nodes):\n",
        "        tmp_history_uv = []\n",
        "        tmp_history_r = []\n",
        "        tmp_userID = []\n",
        "        for node in nodes:\n",
        "            tmp_history_uv.append(self.history_uv_lists[int(node)])\n",
        "            tmp_history_r.append(self.history_r_lists[int(node)])\n",
        "            tmp_userID.append(int(node))\n",
        "\n",
        "        if hasattr(self.aggregator, 'history_t'):\n",
        "            self.aggregator.history_t = self.history_t\n",
        "\n",
        "        neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r, tmp_userID)\n",
        "\n",
        "        self_feats = self.features.weight[nodes]\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjsZUFEDa6q0"
      },
      "source": [
        "# Main Code\n",
        "\n",
        "> GraphRec Definition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6eDi8vn1av5E"
      },
      "outputs": [],
      "source": [
        "class GraphRec(nn.Module):\n",
        "\n",
        "    def __init__(self, enc_u, enc_v_history, r2e):\n",
        "        super(GraphRec, self).__init__()\n",
        "        self.enc_u = enc_u\n",
        "        self.enc_v_history = enc_v_history\n",
        "        self.embed_dim = enc_u.embed_dim\n",
        "\n",
        "        self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
        "        self.w_uv3 = nn.Linear(16, 1)\n",
        "        self.r2e = r2e\n",
        "        self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn4 = nn.BatchNorm1d(16, momentum=0.5)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, nodes_u, nodes_v):\n",
        "        embeds_u = self.enc_u(nodes_u)\n",
        "        embeds_v = self.enc_v_history(nodes_v)\n",
        "\n",
        "        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
        "        x_u = F.dropout(x_u, training=self.training)\n",
        "        x_u = self.w_ur2(x_u)\n",
        "        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
        "        x_v = F.dropout(x_v, training=self.training)\n",
        "        x_v = self.w_vr2(x_v)\n",
        "\n",
        "        x_uv = torch.cat((x_u, x_v), 1)\n",
        "        x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.bn4(self.w_uv2(x)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        scores = self.w_uv3(x)\n",
        "        return scores.squeeze()\n",
        "\n",
        "    def loss(self, nodes_u, nodes_v, labels_list):\n",
        "        scores = self.forward(nodes_u, nodes_v)\n",
        "        return self.criterion(scores, labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ofzWjcW2axiU"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, best_rmse, best_mae, logger):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        batch_nodes_u, batch_nodes_v, labels_list = data\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(batch_nodes_u.to(device), batch_nodes_v.to(device), labels_list.to(device))\n",
        "        # loss.backward(retain_graph=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            log_message = '[%d, %5d] loss: %.3f, The best rmse/mae: %.6f / %.6f' % (\n",
        "                epoch, i, running_loss / 100, best_rmse, best_mae)\n",
        "            logger.info(log_message)\n",
        "            running_loss = 0.0\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x0CYf8_uccvj"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader, logger):\n",
        "    model.eval()\n",
        "    tmp_pred = []\n",
        "    target = []\n",
        "    with torch.no_grad():\n",
        "        for test_u, test_v, tmp_target in test_loader:\n",
        "            test_u, test_v, tmp_target = test_u.to(device), test_v.to(device), tmp_target.to(device)\n",
        "            val_output = model.forward(test_u, test_v)\n",
        "            tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
        "            target.append(list(tmp_target.data.cpu().numpy()))\n",
        "    tmp_pred = np.array(sum(tmp_pred, []))\n",
        "    target = np.array(sum(target, []))\n",
        "    expected_rmse = sqrt(mean_squared_error(tmp_pred, target))\n",
        "    mae = mean_absolute_error(tmp_pred, target)\n",
        "    return expected_rmse, mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E_jaTl80RU0-"
      },
      "outputs": [],
      "source": [
        "def create_checkpoint_dir():\n",
        "    checkpoint_dir = './checkpoints'\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    return checkpoint_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UL61yawhRXqb"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, epoch, rmse, mae, checkpoint_dir, is_best=False, logger=None):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'rmse': rmse,\n",
        "        'mae': mae\n",
        "    }\n",
        "\n",
        "    # Save regular checkpoint\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint.pt')\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "    # Save best model if it's the best so far\n",
        "    if is_best:\n",
        "        best_model_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
        "        torch.save(checkpoint, best_model_path)\n",
        "        log_message = f\"New best model saved! RMSE: {rmse:.4f}, MAE: {mae:.4f}\"\n",
        "        if logger:\n",
        "            logger.info(log_message)\n",
        "        else:\n",
        "            print(log_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iBvwXMkcfAv",
        "outputId": "67b20362-1366-4a5a-83fd-301fa9c7a7df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-21 21:12:45,058 - INFO - ==================================================\n",
            "2025-05-21 21:12:45,059 - INFO - New Training Session Started\n",
            "2025-05-21 21:12:45,059 - INFO - ==================================================\n",
            "2025-05-21 21:12:45,060 - INFO - Log file created at: d:\\workspace\\GraphRec\\logs\\training_log_20250521_211245.txt\n",
            "2025-05-21 21:12:45,061 - INFO - Starting training process...\n",
            "2025-05-21 21:12:45,063 - INFO - Training Configuration:\n",
            "2025-05-21 21:12:45,063 - INFO - Batch Size: 128\n",
            "2025-05-21 21:12:45,064 - INFO - Embedding Dimension: 64\n",
            "2025-05-21 21:12:45,064 - INFO - Learning Rate: 0.001\n",
            "2025-05-21 21:12:45,064 - INFO - Test Batch Size: 1000\n",
            "2025-05-21 21:12:45,065 - INFO - Total Epochs: 20\n",
            "2025-05-21 21:12:45,065 - INFO - Using device: cuda\n",
            "2025-05-21 21:12:46,307 - INFO - Processing timestamps...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNegative timestamp found for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m     invalid_timestamps = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(torch.isnan(torch.tensor(t, dtype=torch.float)) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m timestamps):\n\u001b[32m     66\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNaN timestamp found for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m     invalid_timestamps = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     63\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNegative timestamp found for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m     invalid_timestamps = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(torch.isnan(torch.tensor(t, dtype=torch.float)) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m timestamps):\n\u001b[32m     66\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNaN timestamp found for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m     invalid_timestamps = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Setup logging\n",
        "logger = setup_logging()\n",
        "logger.info(\"Starting training process...\")\n",
        "\n",
        "# Define the arguments as a dictionary\n",
        "args_dict = {\n",
        "    '--batch_size': 128,\n",
        "    '--embed_dim': 64,\n",
        "    '--lr': 0.001,\n",
        "    '--test_batch_size': 1000,\n",
        "    '--epochs': 20,\n",
        "}\n",
        "\n",
        "# Create a list of strings from the dictionary\n",
        "args_list = []\n",
        "for k, v in args_dict.items():\n",
        "    args_list.append(k)\n",
        "    args_list.append(str(v))\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Social Recommendation: GraphRec model')\n",
        "parser.add_argument('--batch_size', type=int, default=128, metavar='N', help='input batch size for training')\n",
        "parser.add_argument('--embed_dim', type=int, default=64, metavar='N', help='embedding size')\n",
        "parser.add_argument('--lr', type=float, default=0.001, metavar='LR', help='learning rate')\n",
        "parser.add_argument('--test_batch_size', type=int, default=1000, metavar='N', help='input batch size for testing')\n",
        "parser.add_argument('--epochs', type=int, default=5, metavar='N', help='number of epochs to train')\n",
        "parser.add_argument('--use_resume', action='store_true', help='resume from checkpoint')\n",
        "args = parser.parse_args(args_list)\n",
        "\n",
        "# Log training configuration\n",
        "logger.info(\"Training Configuration:\")\n",
        "logger.info(f\"Batch Size: {args.batch_size}\")\n",
        "logger.info(f\"Embedding Dimension: {args.embed_dim}\")\n",
        "logger.info(f\"Learning Rate: {args.lr}\")\n",
        "logger.info(f\"Test Batch Size: {args.test_batch_size}\")\n",
        "logger.info(f\"Total Epochs: {args.epochs}\")\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "use_cuda = False\n",
        "if torch.cuda.is_available():\n",
        "    use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "embed_dim = args.embed_dim\n",
        "dir_data = './data/Epinions/pickle/dataset_Epinions_train80val10test10'\n",
        "\n",
        "path_data = dir_data + \".pickle\"\n",
        "data_file = open(path_data, 'rb')\n",
        "history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, train_u, train_v, train_r, val_u, val_v, val_r, test_u, test_v, test_r, social_adj_lists, ratings_list, history_timestamp_lists = pickle.load(data_file)\n",
        "\n",
        "# Validate and normalize timestamps\n",
        "logger.info(\"Processing timestamps...\")\n",
        "\n",
        "# First, validate all timestamps\n",
        "invalid_timestamps = False\n",
        "for user_id, timestamps in history_timestamp_lists.items():\n",
        "    if not timestamps:  # Skip empty lists\n",
        "        continue\n",
        "    if any(not isinstance(t, (int, float)) for t in timestamps):\n",
        "        logger.warning(f\"Invalid timestamp type found for user {user_id}\")\n",
        "        invalid_timestamps = True\n",
        "    if any(t < 0 for t in timestamps):\n",
        "        logger.warning(f\"Negative timestamp found for user {user_id}\")\n",
        "        invalid_timestamps = True\n",
        "    if any(torch.isnan(torch.tensor(t, dtype=torch.float)) for t in timestamps):\n",
        "        logger.warning(f\"NaN timestamp found for user {user_id}\")\n",
        "        invalid_timestamps = True\n",
        "\n",
        "if invalid_timestamps:\n",
        "    logger.warning(\"Found invalid timestamps. Attempting to clean data...\")\n",
        "    # Clean invalid timestamps\n",
        "    for user_id in list(history_timestamp_lists.keys()):\n",
        "        timestamps = history_timestamp_lists[user_id]\n",
        "        valid_timestamps = [t for t in timestamps if isinstance(t, (int, float)) and t >= 0 and not torch.isnan(torch.tensor(t, dtype=torch.float))]\n",
        "        if valid_timestamps:\n",
        "            history_timestamp_lists[user_id] = valid_timestamps\n",
        "        else:\n",
        "            # If no valid timestamps, use a default value\n",
        "            history_timestamp_lists[user_id] = [0.0] * len(history_u_lists[user_id])\n",
        "            logger.warning(f\"User {user_id} had no valid timestamps. Using default values.\")\n",
        "\n",
        "# Get global min and max timestamps\n",
        "logger.info(\"Calculating global timestamp range...\")\n",
        "all_timestamps = []\n",
        "for timestamps in history_timestamp_lists.values():\n",
        "    all_timestamps.extend(timestamps)\n",
        "\n",
        "global_min = min(all_timestamps)\n",
        "global_max = max(all_timestamps)\n",
        "logger.info(f\"Global timestamp range: {global_min:.2f} to {global_max:.2f}\")\n",
        "\n",
        "# Normalize timestamps using global min and max\n",
        "logger.info(\"Normalizing timestamps using global range...\")\n",
        "normalized_history_timestamp_lists = {}\n",
        "\n",
        "for user_id, timestamps in history_timestamp_lists.items():\n",
        "    if not timestamps:  # Skip empty lists\n",
        "        normalized_history_timestamp_lists[user_id] = []\n",
        "        continue\n",
        "\n",
        "    # Normalize using global min and max\n",
        "    if global_max > global_min:\n",
        "        normalized_timestamps = [(t - global_min) / (global_max - global_min) for t in timestamps]\n",
        "    else:\n",
        "        # If all timestamps are the same, set to 0.5\n",
        "        normalized_timestamps = [0.5] * len(timestamps)\n",
        "\n",
        "    normalized_history_timestamp_lists[user_id] = normalized_timestamps\n",
        "\n",
        "    # Log some statistics for verification\n",
        "    # if user_id % 1000 == 0:  # Log every 1000th user\n",
        "    #     logger.info(f\"User {user_id} timestamp stats:\")\n",
        "    #     logger.info(f\"  Original range: {min(timestamps):.2f} to {max(timestamps):.2f}\")\n",
        "    #     logger.info(f\"  Normalized range: {min(normalized_timestamps):.2f} to {max(normalized_timestamps):.2f}\")\n",
        "    #     logger.info(f\"  Number of timestamps: {len(normalized_timestamps)}\")\n",
        "\n",
        "# Replace original timestamps with normalized ones\n",
        "history_timestamp_lists = normalized_history_timestamp_lists\n",
        "logger.info(\"Timestamp normalization completed\")\n",
        "\n",
        "trainset = torch.utils.data.TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v),\n",
        "                                        torch.FloatTensor(train_r))\n",
        "testset = torch.utils.data.TensorDataset(torch.LongTensor(val_u), torch.LongTensor(val_v),\n",
        "                                        torch.FloatTensor(val_r))\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=True)\n",
        "num_users = history_u_lists.__len__()\n",
        "num_items = history_v_lists.__len__()\n",
        "num_ratings = ratings_list.__len__()\n",
        "\n",
        "logger.info(f\"Dataset loaded: {num_users} users, {num_items} items, {num_ratings} ratings\")\n",
        "\n",
        "u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
        "v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
        "r2e = nn.Embedding(num_ratings, embed_dim).to(device)\n",
        "lamda = 1.0\n",
        "\n",
        "# user feature\n",
        "agg_u_history = UV_Aggregator(v2e, r2e, u2e, history_timestamp_lists, lamda, embed_dim, cuda=device, uv=True)\n",
        "enc_u_history = UV_Encoder(u2e, embed_dim, history_u_lists, history_ur_lists, history_timestamp_lists, agg_u_history, cuda=device, uv=True)\n",
        "\n",
        "# neighbors\n",
        "agg_u_social = Social_Aggregator(lambda nodes: enc_u_history(nodes).t(), u2e, embed_dim, cuda=device)\n",
        "enc_u = Social_Encoder(lambda nodes: enc_u_history(nodes).t(), embed_dim, social_adj_lists, agg_u_social,\n",
        "                      base_model=enc_u_history, cuda=device)\n",
        "\n",
        "# item feature\n",
        "agg_v_history = UV_Aggregator(v2e, r2e, u2e, history_timestamp_lists, lamda, embed_dim, cuda=device, uv=False)\n",
        "enc_v_history = UV_Encoder(v2e, embed_dim, history_v_lists, history_vr_lists, history_timestamp_lists, agg_v_history, cuda=device, uv=False)\n",
        "\n",
        "# model\n",
        "graphrec = GraphRec(enc_u, enc_v_history, r2e).to(device)\n",
        "optimizer = torch.optim.RMSprop(graphrec.parameters(), lr=args.lr, alpha=0.9)\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint_path = './checkpoints/best_model.pt'\n",
        "args.use_resume = True\n",
        "if os.path.exists(checkpoint_path) and args.use_resume:\n",
        "    logger.info(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    graphrec.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Start from next epoch\n",
        "    best_rmse = checkpoint['rmse']\n",
        "    best_mae = checkpoint['mae']\n",
        "    logger.info(f\"Resuming from epoch {start_epoch}\")\n",
        "    logger.info(f\"Previous best RMSE: {best_rmse:.4f}, MAE: {best_mae:.4f}\")\n",
        "else:\n",
        "    logger.info(\"No checkpoint found, starting from scratch\")\n",
        "    start_epoch = 1\n",
        "    best_rmse = 9999.0\n",
        "    best_mae = 9999.0\n",
        "\n",
        "# Create checkpoint directory\n",
        "checkpoint_dir = create_checkpoint_dir()\n",
        "\n",
        "endure_count = 0\n",
        "logger.info(f'Total epochs: {args.epochs}')\n",
        "\n",
        "for epoch in range(start_epoch, args.epochs + 1):\n",
        "    train(graphrec, device, train_loader, optimizer, epoch, best_rmse, best_mae, logger)\n",
        "    expected_rmse, mae = test(graphrec, device, test_loader, logger)\n",
        "\n",
        "    # Early stopping\n",
        "    if best_rmse > expected_rmse:\n",
        "        best_rmse = expected_rmse\n",
        "        best_mae = mae\n",
        "        endure_count = 0\n",
        "        # Save best model\n",
        "        save_checkpoint(graphrec, optimizer, epoch, expected_rmse, mae, checkpoint_dir, is_best=True, logger=logger)\n",
        "    else:\n",
        "        endure_count += 1\n",
        "    logger.info(f\"Epoch {epoch} - RMSE: {expected_rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "    if endure_count > 5:\n",
        "        logger.info(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "logger.info(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KryxG0vQeYaZ"
      },
      "source": [
        "# 結果如上"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GraphRec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
