{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw02vWCGbLNK"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gxk77J8yZuPt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import torch.utils.data\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from math import sqrt\n",
        "import datetime\n",
        "import argparse\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import logging\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcJ24B1QbP2X"
      },
      "source": [
        "# Define Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aq8FTov7aSHW"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, embedding_dims):\n",
        "        super(Attention, self).__init__()\n",
        "        self.embed_dim = embedding_dims\n",
        "        self.bilinear = nn.Bilinear(self.embed_dim, self.embed_dim, 1)\n",
        "        self.att1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.att2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att3 = nn.Linear(self.embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(0)\n",
        "\n",
        "    def forward(self, node1, u_rep, num_neighs):\n",
        "        uv_reps = u_rep.repeat(num_neighs, 1)\n",
        "        x = torch.cat((node1, uv_reps), 1)\n",
        "        x = F.relu(self.att1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.att2(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.att3(x)\n",
        "        att = F.softmax(x, dim=0)\n",
        "        return att"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ubEsXapZaToS"
      },
      "outputs": [],
      "source": [
        "class Social_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, social_adj_lists, aggregator, base_model=None, cuda=\"cpu\"):\n",
        "        super(Social_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.social_adj_lists = social_adj_lists\n",
        "        self.aggregator = aggregator\n",
        "        if base_model != None:\n",
        "            self.base_model = base_model\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "\n",
        "        to_neighs = []\n",
        "        for node in nodes:\n",
        "            # to_neighs.append(self.social_adj_lists[int(node)])\n",
        "            to_neighs.append(self.social_adj_lists.get(int(node), set())) # Use .get() with default empty set for missing users\n",
        "        neigh_feats = self.aggregator.forward(nodes, to_neighs)  # user-user network\n",
        "\n",
        "        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)\n",
        "        self_feats = self_feats.t()\n",
        "\n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "162geY4UaWO4"
      },
      "outputs": [],
      "source": [
        "class Social_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    Social Aggregator: for aggregating embeddings of social neighbors.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, features, u2e, embed_dim, cuda=\"cpu\"):\n",
        "        super(Social_Aggregator, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.device = cuda\n",
        "        self.u2e = u2e\n",
        "        self.embed_dim = embed_dim\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, to_neighs):\n",
        "        embed_matrix = torch.empty(len(nodes), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "        for i in range(len(nodes)):\n",
        "            tmp_adj = to_neighs[i]\n",
        "            num_neighs = len(tmp_adj)\n",
        "            e_u = self.u2e.weight[list(tmp_adj)] # fast: user embedding\n",
        "            #slow: item-space user latent factor (item aggregation)\n",
        "            #feature_neigbhors = self.features(torch.LongTensor(list(tmp_adj)).to(self.device))\n",
        "            #e_u = torch.t(feature_neigbhors)\n",
        "\n",
        "            u_rep = self.u2e.weight[nodes[i]]\n",
        "\n",
        "            att_w = self.att(e_u, u_rep, num_neighs)\n",
        "            att_history = torch.mm(e_u.t(), att_w).t()\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "\n",
        "        return to_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sWlis_Kgadle"
      },
      "outputs": [],
      "source": [
        "class UV_Aggregator(nn.Module):\n",
        "    \"\"\"\n",
        "    item and user aggregator: for aggregating embeddings of neighbors (item/user aggreagator).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, v2e, r2e, u2e, embed_dim, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Aggregator, self).__init__()\n",
        "        self.uv = uv\n",
        "        self.v2e = v2e\n",
        "        self.r2e = r2e\n",
        "        self.u2e = u2e\n",
        "        self.device = cuda\n",
        "        self.embed_dim = embed_dim\n",
        "        self.w_r1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_r2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.att = Attention(self.embed_dim)\n",
        "\n",
        "    def forward(self, nodes, history_uv, history_r):\n",
        "\n",
        "        embed_matrix = torch.empty(len(history_uv), self.embed_dim, dtype=torch.float).to(self.device)\n",
        "\n",
        "        for i in range(len(history_uv)):\n",
        "            history = history_uv[i]\n",
        "            num_histroy_item = len(history)\n",
        "            tmp_label = history_r[i]\n",
        "\n",
        "            if self.uv == True:\n",
        "                # user component\n",
        "                e_uv = self.v2e.weight[history]\n",
        "                uv_rep = self.u2e.weight[nodes[i]]\n",
        "            else:\n",
        "                # item component\n",
        "                e_uv = self.u2e.weight[history]\n",
        "                uv_rep = self.v2e.weight[nodes[i]]\n",
        "\n",
        "            e_r = self.r2e.weight[tmp_label]\n",
        "            x = torch.cat((e_uv, e_r), 1)\n",
        "            x = F.relu(self.w_r1(x))\n",
        "            o_history = F.relu(self.w_r2(x))\n",
        "\n",
        "            att_w = self.att(o_history, uv_rep, num_histroy_item)\n",
        "            att_history = torch.mm(o_history.t(), att_w)\n",
        "            att_history = att_history.t()\n",
        "\n",
        "            embed_matrix[i] = att_history\n",
        "        to_feats = embed_matrix\n",
        "        return to_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1Y4oueU0aiTo"
      },
      "outputs": [],
      "source": [
        "class UV_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, features, embed_dim, history_uv_lists, history_r_lists, aggregator, cuda=\"cpu\", uv=True):\n",
        "        super(UV_Encoder, self).__init__()\n",
        "\n",
        "        self.features = features\n",
        "        self.uv = uv\n",
        "        self.history_uv_lists = history_uv_lists\n",
        "        self.history_r_lists = history_r_lists\n",
        "        self.aggregator = aggregator\n",
        "        self.embed_dim = embed_dim\n",
        "        self.device = cuda\n",
        "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim)  #\n",
        "\n",
        "    def forward(self, nodes):\n",
        "        tmp_history_uv = []\n",
        "        tmp_history_r = []\n",
        "        for node in nodes:\n",
        "            tmp_history_uv.append(self.history_uv_lists[int(node)])\n",
        "            tmp_history_r.append(self.history_r_lists[int(node)])\n",
        "\n",
        "        neigh_feats = self.aggregator.forward(nodes, tmp_history_uv, tmp_history_r)  # user-item network\n",
        "\n",
        "        self_feats = self.features.weight[nodes]\n",
        "        # self-connection could be considered.\n",
        "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
        "        combined = F.relu(self.linear1(combined))\n",
        "\n",
        "        return combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjsZUFEDa6q0"
      },
      "source": [
        "# Main Code\n",
        "\n",
        "> GraphRec Definition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "6eDi8vn1av5E"
      },
      "outputs": [],
      "source": [
        "class GraphRec(nn.Module):\n",
        "\n",
        "    def __init__(self, enc_u, enc_v_history, r2e):\n",
        "        super(GraphRec, self).__init__()\n",
        "        self.enc_u = enc_u\n",
        "        self.enc_v_history = enc_v_history\n",
        "        self.embed_dim = enc_u.embed_dim\n",
        "\n",
        "        self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
        "        self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
        "        self.w_uv3 = nn.Linear(16, 1)\n",
        "        self.r2e = r2e\n",
        "        self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
        "        self.bn4 = nn.BatchNorm1d(16, momentum=0.5)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, nodes_u, nodes_v):\n",
        "        embeds_u = self.enc_u(nodes_u)\n",
        "        embeds_v = self.enc_v_history(nodes_v)\n",
        "\n",
        "        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
        "        x_u = F.dropout(x_u, training=self.training)\n",
        "        x_u = self.w_ur2(x_u)\n",
        "        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
        "        x_v = F.dropout(x_v, training=self.training)\n",
        "        x_v = self.w_vr2(x_v)\n",
        "\n",
        "        x_uv = torch.cat((x_u, x_v), 1)\n",
        "        x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.bn4(self.w_uv2(x)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        scores = self.w_uv3(x)\n",
        "        return scores.squeeze()\n",
        "\n",
        "    def loss(self, nodes_u, nodes_v, labels_list):\n",
        "        scores = self.forward(nodes_u, nodes_v)\n",
        "        return self.criterion(scores, labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ofzWjcW2axiU"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, best_rmse, best_mae):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        batch_nodes_u, batch_nodes_v, labels_list = data\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(batch_nodes_u.to(device), batch_nodes_v.to(device), labels_list.to(device))\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            print('[%d, %5d] loss: %.3f, The best rmse/mae: %.6f / %.6f' % (\n",
        "                epoch, i, running_loss / 100, best_rmse, best_mae))\n",
        "            running_loss = 0.0\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "x0CYf8_uccvj"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    tmp_pred = []\n",
        "    target = []\n",
        "    with torch.no_grad():\n",
        "        for test_u, test_v, tmp_target in test_loader:\n",
        "            test_u, test_v, tmp_target = test_u.to(device), test_v.to(device), tmp_target.to(device)\n",
        "            val_output = model.forward(test_u, test_v)\n",
        "            tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
        "            target.append(list(tmp_target.data.cpu().numpy()))\n",
        "    tmp_pred = np.array(sum(tmp_pred, []))\n",
        "    target = np.array(sum(target, []))\n",
        "    expected_rmse = sqrt(mean_squared_error(tmp_pred, target))\n",
        "    mae = mean_absolute_error(tmp_pred, target)\n",
        "    return expected_rmse, mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "E_jaTl80RU0-"
      },
      "outputs": [],
      "source": [
        "def create_checkpoint_dir():\n",
        "    checkpoint_dir = './checkpoints'\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    return checkpoint_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UL61yawhRXqb"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, epoch, rmse, mae, checkpoint_dir, is_best=False):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'rmse': rmse,\n",
        "        'mae': mae\n",
        "    }\n",
        "\n",
        "    # Save regular checkpoint\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint.pt')\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "    # Save best model if it's the best so far\n",
        "    if is_best:\n",
        "        best_model_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
        "        torch.save(checkpoint, best_model_path)\n",
        "        print(f\"New best model saved! RMSE: {rmse:.4f}, MAE: {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_logging():\n",
        "    # Create logs directory if it doesn't exist\n",
        "    log_dir = os.path.join(os.getcwd(), 'logs')\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "\n",
        "    # Create a log file with timestamp\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    log_file = os.path.join(log_dir, f'training_log_{timestamp}.txt')\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file, encoding='utf-8'),\n",
        "            logging.StreamHandler()  # This will also print to console\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Create logger\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Log the start of a new training session\n",
        "    logger.info(\"=\"*50)\n",
        "    logger.info(\"New Training Session Started\")\n",
        "    logger.info(\"=\"*50)\n",
        "    logger.info(f\"Log file created at: {log_file}\")\n",
        "\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iBvwXMkcfAv",
        "outputId": "59874b6f-b156-4c81-fc97-ddf1ae681278"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-23 03:01:34,381 - INFO - ==================================================\n",
            "2025-05-23 03:01:34,382 - INFO - New Training Session Started\n",
            "2025-05-23 03:01:34,382 - INFO - ==================================================\n",
            "2025-05-23 03:01:34,383 - INFO - Log file created at: /home/user/Andy/GraphRec/logs/training_log_20250523_030134.txt\n",
            "2025-05-23 03:01:34,383 - INFO - Starting training process...\n",
            "2025-05-23 03:01:34,384 - INFO - Training Configuration:\n",
            "2025-05-23 03:01:34,384 - INFO - Batch Size: 128\n",
            "2025-05-23 03:01:34,385 - INFO - Embedding Dimension: 64\n",
            "2025-05-23 03:01:34,385 - INFO - Learning Rate: 0.001\n",
            "2025-05-23 03:01:34,385 - INFO - Test Batch Size: 1000\n",
            "2025-05-23 03:01:34,385 - INFO - Total Epochs: 100\n",
            "2025-05-23 03:01:34,386 - INFO - Using device: cuda\n",
            "2025-05-23 03:01:35,066 - INFO - No checkpoint found, starting from scratch\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total epoch:100\n",
            "[1,     0] loss: 0.177, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   100] loss: 14.969, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   200] loss: 8.972, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   300] loss: 4.835, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   400] loss: 2.670, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   500] loss: 2.137, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   600] loss: 1.889, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   700] loss: 1.771, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   800] loss: 1.684, The best rmse/mae: 9999.000000 / 9999.000000\n",
            "[1,   900] loss: 1.579, The best rmse/mae: 9999.000000 / 9999.000000\n"
          ]
        }
      ],
      "source": [
        "# Setup logging\n",
        "logger = setup_logging()\n",
        "logger.info(\"Starting training process...\")\n",
        "\n",
        "# Define the arguments as a dictionary\n",
        "args_dict = {\n",
        "    '--batch_size': 128,\n",
        "    '--embed_dim': 64,\n",
        "    '--lr': 0.001,\n",
        "    '--test_batch_size': 1000,\n",
        "    '--epochs': 100\n",
        "}\n",
        "\n",
        "# Create a list of strings from the dictionary\n",
        "args_list = []\n",
        "for k, v in args_dict.items():\n",
        "    args_list.append(k)\n",
        "    args_list.append(str(v))\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Social Recommendation: GraphRec model')\n",
        "parser.add_argument('--batch_size', type=int, default=128, metavar='N', help='input batch size for training')\n",
        "parser.add_argument('--embed_dim', type=int, default=64, metavar='N', help='embedding size')\n",
        "parser.add_argument('--lr', type=float, default=0.001, metavar='LR', help='learning rate')\n",
        "parser.add_argument('--test_batch_size', type=int, default=1000, metavar='N', help='input batch size for testing')\n",
        "parser.add_argument('--epochs', type=int, default=100, metavar='N', help='number of epochs to train')\n",
        "args = parser.parse_args(args_list) # Pass the list to parse_args\n",
        "\n",
        "# Log training configuration\n",
        "logger.info(\"Training Configuration:\")\n",
        "logger.info(f\"Batch Size: {args.batch_size}\")\n",
        "logger.info(f\"Embedding Dimension: {args.embed_dim}\")\n",
        "logger.info(f\"Learning Rate: {args.lr}\")\n",
        "logger.info(f\"Test Batch Size: {args.test_batch_size}\")\n",
        "logger.info(f\"Total Epochs: {args.epochs}\")\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "use_cuda = False\n",
        "if torch.cuda.is_available():\n",
        "\tuse_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "embed_dim = args.embed_dim\n",
        "# dir_data = './Epinions/dataset_Epinions'\n",
        "dir_data = './data/Epinions/dataset_Epinions_train60val20test20'\n",
        "\n",
        "path_data = dir_data + \".pickle\"\n",
        "data_file = open(path_data, 'rb')\n",
        "history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, train_u, train_v, train_r, val_u, val_v, val_r, test_u, test_v, test_r, social_adj_lists, ratings_list, history_timestamp_lists = pickle.load(data_file)\n",
        "\n",
        "\"\"\"\n",
        "## toy dataset\n",
        "history_u_lists, history_ur_lists:  user's purchased history (item set in training set), and his/her rating score (dict)\n",
        "history_v_lists, history_vr_lists:  user set (in training set) who have interacted with the item, and rating score (dict)\n",
        "\n",
        "train_u, train_v, train_r: training_set (user, item, rating)\n",
        "test_u, test_v, test_r: testing set (user, item, rating)\n",
        "\n",
        "# please add the validation set\n",
        "\n",
        "social_adj_lists: user's connected neighborhoods\n",
        "ratings_list: rating value from 0.5 to 4.0 (8 opinion embeddings)\n",
        "\"\"\"\n",
        "\n",
        "trainset = torch.utils.data.TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v),\n",
        "\t\t\t\t\t\t\t\t\t\t  torch.FloatTensor(train_r))\n",
        "testset = torch.utils.data.TensorDataset(torch.LongTensor(val_u), torch.LongTensor(val_v),\n",
        "\t\t\t\t\t\t\t\t\t\t torch.FloatTensor(val_r))\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=True)\n",
        "num_users = history_u_lists.__len__()\n",
        "num_items = history_v_lists.__len__()\n",
        "num_ratings = ratings_list.__len__()\n",
        "\n",
        "u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
        "v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
        "r2e = nn.Embedding(num_ratings, embed_dim).to(device)\n",
        "\n",
        "# user feature\n",
        "# features: item * rating\n",
        "agg_u_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=True)\n",
        "enc_u_history = UV_Encoder(u2e, embed_dim, history_u_lists, history_ur_lists, agg_u_history, cuda=device, uv=True)\n",
        "# neighobrs\n",
        "agg_u_social = Social_Aggregator(lambda nodes: enc_u_history(nodes).t(), u2e, embed_dim, cuda=device)\n",
        "enc_u = Social_Encoder(lambda nodes: enc_u_history(nodes).t(), embed_dim, social_adj_lists, agg_u_social,\n",
        "\t\t\t\t\t   base_model=enc_u_history, cuda=device)\n",
        "\n",
        "# item feature: user * rating\n",
        "agg_v_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, cuda=device, uv=False)\n",
        "enc_v_history = UV_Encoder(v2e, embed_dim, history_v_lists, history_vr_lists, agg_v_history, cuda=device, uv=False)\n",
        "\n",
        "# model\n",
        "graphrec = GraphRec(enc_u, enc_v_history, r2e).to(device)\n",
        "optimizer = torch.optim.RMSprop(graphrec.parameters(), lr=args.lr, alpha=0.9)\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint_path = './checkpoints/best_model.pt'\n",
        "args.use_resume = False\n",
        "if os.path.exists(checkpoint_path) and args.use_resume:\n",
        "    logger.info(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    graphrec.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Start from next epoch\n",
        "    best_rmse = checkpoint['rmse']\n",
        "    best_mae = checkpoint['mae']\n",
        "    logger.info(f\"Resuming from epoch {start_epoch}\")\n",
        "    logger.info(f\"Previous best RMSE: {best_rmse:.4f}, MAE: {best_mae:.4f}\")\n",
        "else:\n",
        "    logger.info(\"No checkpoint found, starting from scratch\")\n",
        "    start_epoch = 1\n",
        "    best_rmse = 9999.0\n",
        "    best_mae = 9999.0\n",
        "\n",
        "# Create checkpoint directory\n",
        "checkpoint_dir = create_checkpoint_dir()\n",
        "\n",
        "best_rmse = 9999.0\n",
        "best_mae = 9999.0\n",
        "endure_count = 0\n",
        "\n",
        "print(f'total epoch:{args.epochs}')\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "\n",
        "\ttrain(graphrec, device, train_loader, optimizer, epoch, best_rmse, best_mae)\n",
        "\texpected_rmse, mae = test(graphrec, device, test_loader)\n",
        "\t# please add the validation set to tune the hyper-parameters based on your datasets.\n",
        "\n",
        "\t# early stopping (no validation set in toy dataset)\n",
        "\tif best_rmse > expected_rmse:\n",
        "\t\tbest_rmse = expected_rmse\n",
        "\t\tbest_mae = mae\n",
        "\t\tendure_count = 0\n",
        "\t\t# Save best model\n",
        "\t\tsave_checkpoint(graphrec, optimizer, epoch, expected_rmse, mae, checkpoint_dir, is_best=True)\n",
        "\telse:\n",
        "\t\tendure_count += 1\n",
        "\tlogger.info(f\"Epoch {epoch} - RMSE: {expected_rmse:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "\tif endure_count > 5:\n",
        "\t\tlogger.info(\"Early stopping triggered\")\n",
        "\t\tbreak\n",
        "\n",
        "logger.info(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KryxG0vQeYaZ"
      },
      "source": [
        "# 結果如上"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GraphRec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipyt